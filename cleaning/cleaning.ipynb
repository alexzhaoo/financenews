{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data# This is a markdown cell\n",
    "Markdown cell is used to describe and document your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/VSCodeProjects/financenews/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/34/4m3rx1zd32dgvl3g8t313g900000gn/T/ipykernel_14737/1730059594.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    3, 26446, 24960,  ...,     0,     0,     0],\n",
      "        [    3,     6,   273,  ...,     0,     0,     0],\n",
      "        [    3,    20,     6,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    3,     6, 14856,  ...,     0,     0,     0],\n",
      "        [    3,     6, 21868,  ...,     0,     0,     0],\n",
      "        [    3,     6,  3536,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "PyTorch version: 2.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/34/4m3rx1zd32dgvl3g8t313g900000gn/T/ipykernel_14737/1730059594.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    3,    26,    17,  ...,    11, 11833,     4],\n",
      "        [    3, 10917,  5004,  ...,     0,     0,     0],\n",
      "        [    3,  4454,   510,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    3,    33,  3925,  ...,     0,     0,     0],\n",
      "        [    3,   657, 22559,  ...,     0,     0,     0],\n",
      "        [    3,    11,  7258,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def cleaning(inputpath, outputpath):\n",
    "    df = pd.read_csv(inputpath)\n",
    "\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].apply(lambda x: re.sub(r'[^A-Za-z0-9 ]+', '', str(x)) if pd.notnull(x) else '')\n",
    "    df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "    # Check if PyTorch is correctly imported\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "    tokens = tokenizer(df[\"sentence\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    print(tokens)\n",
    "    df.to_csv(outputpath, index=False)\n",
    "\n",
    "cleaning('../datasets/PositiveLabel.csv', '../datasets/PositiveLabel.csv')\n",
    "cleaning('../datasets/NegativeLabel.csv', '../datasets/NegativeLabel.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
